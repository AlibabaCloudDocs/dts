# 从自建TiDB增量迁移至RDS MySQL

本文介绍如何使用数据传输服务DTS（Data Transmission Service），结合Kafka集群与TiDB数据库的Pump、Drainer组件，完成增量数据迁移，实现在应用不停服的情况下，平滑地完成数据库的迁移上云。

[创建RDS MySQL实例](/cn.zh-CN/RDS MySQL 数据库/快速入门/创建RDS MySQL实例.md)

**说明：**

-   由于该功能仅在部分地域支持，目标RDS MySQL实例所属的地域需为华东1（杭州）、华东2（上海）、华北1（青岛）、华北2（北京）、华南1（深圳）、华北3（张家口）、中国香港、亚太东南1（新加坡）、美国西部1（硅谷）或美国东部1（弗吉利亚）地域。
-   RDS MySQL实例的存储空间须大于TiDB数据库已占用的存储空间。

![TiDB增量迁移架构图](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/8197549951/p113300.png)

由于TiDB的Binlog格式和实现机制与MySQL数据库存在一定区别，为实现增量数据迁移，同时减少对源数据库的改动，您需要部署Kafka集群以及TiDB数据库的Pump和Drainer组件。

由Pump组件实时记录TiDB产生的Binlog并提供给Drainer组件，然后由Drainer组件将获取到的Binlog写入到下游的Kafka集群。DTS在执行增量数据迁移时将从Kafka集群中获取对应的数据并实时迁移至目标数据库（例如RDS MySQL实例）。

## 注意事项

-   DTS在执行全量数据迁移时将占用源库和目标库一定的读写资源，可能会导致数据库的负载上升，在数据库性能较差、规格较低或业务量较大的情况下（例如源库有大量慢SQL、存在无主键表或目标库存在死锁等），可能会加重数据库压力，甚至导致数据库服务不可用。因此您需要在执行数据迁移前评估源库和目标库的性能，同时建议您在业务低峰期执行数据迁移（例如源库和目标库的CPU负载在30%以下）。
-   如果源库中待迁移的表没有主键或唯一约束，且所有字段没有唯一性，可能会导致目标数据库中出现重复数据。
-   对于数据类型为FLOAT或DOUBLE的列，DTS会通过`ROUND(COLUMN,PRECISION)`来读取该列的值。如果没有明确定义其精度，DTS对FLOAT的迁移精度为38位，对DOUBLE的迁移精度为308位，请确认迁移精度是否符合业务预期。
-   DTS会自动地在阿里云RDS MySQL中创建数据库，如果待迁移的数据库名称不符合阿里云RDS的定义规范，您需要在配置迁移任务之前在阿里云RDS MySQL中创建数据库。

    **说明：** 关于阿里云RDS的定义规范和创建数据库的操作方法，请参见[创建数据库](https://help.aliyun.com/document_detail/96105.html)。

-   对于迁移失败的任务，DTS会触发自动恢复。在您将业务切换至目标实例前，请务必先结束或释放该任务，避免该任务被自动恢复后，导致源端数据覆盖目标实例的数据。

## 费用说明

|迁移类型|链路配置费用|公网流量费用|
|----|------|------|
|结构迁移和全量数据迁移|不收费。|通过公网将数据迁移出阿里云时将收费，详情请参见[产品定价](/cn.zh-CN/产品定价/产品定价.md)。|
|增量数据迁移|收费，详情请参见[产品定价](/cn.zh-CN/产品定价/产品定价.md)。|

## 迁移类型说明

|迁移类型|说明|
|----|--|
|结构迁移|DTS将待迁移对象的结构定义迁移到目标库。目前DTS支持结构迁移的对象为库、表和视图。 **警告：** 此场景属于异构数据库间的数据迁移，DTS在执行结构迁移时数据类型无法完全对应，请谨慎评估数据类型的映射关系对业务的影响，详情请参见[异构数据库间的数据类型映射关系](/cn.zh-CN/数据迁移/异构数据库间的数据类型映射关系.md)。 |
|全量数据迁移|DTS将待迁移对象的存量数据全部迁移到目标库中。 **说明：** 由于全量数据迁移会并发INSERT导致目标实例的表存在碎片，全量迁移完成后目标库的表空间会比源库的表空间大。 |
|增量数据迁移|DTS从Kafka集群中获取TiDB产生的Binlog数据，然后将对应的增量更新实时迁移至到目标库中。增量数据迁移阶段支持下列SQL操作的同步： -   DML：INSERT、UPDATE、DELETE
-   DDL：CREATE TABLE、DROP TABLE、ALTER TABLE、RENAME TABLE、TRUNCATE TABLE、CREATE VIEW、DROP VIEW、ALTER VIEW

通过增量数据迁移可以实现在应用不停服的情况下，平滑地完成数据库的迁移上云。 |

## 准备工作

**说明：** 为减少网络延迟对增量数据迁移的影响，Pump组件、Drainer组件和Kafka集群所部署的服务器需要与源库所属的服务器在同一内网中。

1.  部署Pump和Drainer组件，详情请参见[TiDB Binlog集群部署](https://pingcap.com/docs-cn/stable/tidb-binlog/deploy-tidb-binlog/)。

2.  修改Drainer组件的配置文件，设置输出为Kafka，详情请参见[Kafka自定义开发](https://pingcap.com/docs-cn/stable/tidb-binlog/binlog-slave-client/)。

3.  选择下述方法准备Kafka集群：

    -   部署自建Kafka集群，详情请参见[Apache Kafka官网](https://kafka.apache.org/)。

        **警告：** 为保障Kafka集群可正常接收到TiDB产生的较大的Binlog数据，请适当将Broker组件中的`message.max.bytes`、`replica.fetch.max.bytes`参数以及Consumer组件中的`fetch.message.max.bytes`参数对应的值调大，详细说明请参见[Kafka配置说明](https://kafka.apache.org/documentation/#configuration)。

    -   使用[阿里云消息队列Kafka版（MQ for Apache Kafka）](/cn.zh-CN/产品简介/什么是消息队列Kafka版？.md)，详情请参见[阿里云消息队列Kafka版快速入门](/cn.zh-CN/快速入门/概述.md)。

        **说明：** 为保障正常通信和减少网络延迟对增量数据迁移的影响，部署阿里云消息队列Kafka实例时，需配置和源库服务器相同的专有网络。

4.  在自建Kafka集群或阿里云消息队列Kafka实例中创建Topic。

5.  将DTS服务器的IP地址段加入至TiDB数据库的白名单安全设置中，具体IP地址段信息请参见[迁移、同步或订阅本地数据库时需添加的IP白名单](/cn.zh-CN/准备工作/迁移、同步或订阅本地数据库时需添加的IP白名单.md)。


## 操作步骤

1.  登录[数据传输控制台](https://dts.console.aliyun.com/)。

2.  在左侧导航栏，单击**数据迁移**。

3.  在迁移任务列表页面顶部，选择迁移的目标集群所属地域。

    ![选择地域](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/2767559951/p50439.png)

4.  单击页面右上角的**创建迁移任务**。

5.  配置迁移任务的源库及目标库信息。

    1.  配置迁移任务的名称和源库信息。

        ![配置名称和源库信息](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/8197549951/p113247.png)

        |配置|说明|
        |:-|:-|
        |任务名称|DTS会自动生成一个任务名称，建议配置具有业务意义的名称（无唯一性要求），便于后续识别。|
        |实例类型|根据源库的部署位置进行选择， 本文以**ECS上的自建数据库**为例介绍配置流程。 **说明：** 当自建数据库为其他实例类型时，您还需要执行相应的准备工作，详情请参见[准备工作概览](/cn.zh-CN/准备工作/准备工作概览.md)。 |
        |实例地区|选择部署了TiDB数据库的ECS实例所属的地域。|
        |数据库类型|选择**TiDB**。|
        |端口|填入TiDB数据库的服务端口，默认为**4000**。|
        |数据库账号|填入TiDB数据库账号，需具备SHOW VIEW和待迁移对象的SELECT权限。|
        |数据库密码|填入该数据库账号的密码。 **说明：** 源库信息填写完毕后，您可以单击**数据库密码**后的**测试连接**来验证填入的源库信息是否正确。源库信息填写正确则提示**测试通过**；如果提示**测试失败**，单击**测试失败**后的**诊断**，根据提示调整填写的源库信息。 |
        |是否做增量迁移|根据业务需求选择，本案例选择为**是**。如果仅需要全量数据迁移，配置方法请参见[从自建TiDB全量迁移至RDS MySQL](/cn.zh-CN/数据迁移/从自建数据库迁移至阿里云/源库为TiDB/从自建TiDB全量迁移至RDS MySQL.md)。|
        |Kafka集群类型|根据Kafka的部署位置进行选择， 本文以**ECS上的自建数据库**为例介绍配置流程。当自建Kafka为其他实例类型时，您还需要执行相应的准备工作，详情请参见[准备工作概览](/cn.zh-CN/准备工作/准备工作概览.md)。 **说明：** 由于DTS暂时不支持直接选择阿里云消息队列Kafka版，如果您使用的是阿里云消息队列Kafka实例，此处需将其作为自建Kafka来配置，即选择为**通过专线/VPN网关/智能接入网关接入的自建数据库**，然后选择阿里云消息队列Kafka实例所属的专有网络。 |
        |实例地区|和源库的实例地区保持一致，不可变更。|
        |ECS实例ID|选择自建Kafka所属的ECS实例ID。|
        |Kafka端口|自建Kafka的服务端口，默认为9092。|
        |Kafka集群账号|填入自建Kafka的用户名，如自建Kafka未开启验证可不填写。|
        |Kafka集群密码|填入该用户的密码，如自建Kafka未开启验证可不填写。|
        |Topic|单击右侧的**获取Topic列表**，然后在下拉框中选择具体的Topic。|
        |Kafka版本|根据自建Kafka的版本进行选择。|
        |Kafka集群连接方式|根据业务及安全需求，选择**非加密连接**或**SCRAM-SHA-256**。|

    2.  配置迁移任务的目标库信息。

        ![配置目标库信息](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/9197549951/p113250.png)

        |配置|说明|
        |:-|:-|
        |实例类型|选择**RDS实例**。|
        |实例地区|选择目标RDS实例所属地域。|
        |数据库账号|填入目标RDS实例的数据库账号，需具备目标库的读写权限。数据库账号的创建及授权方法请参见[创建账号](https://help.aliyun.com/document_detail/96089.html)和[修改账号权限](https://help.aliyun.com/document_detail/96101.html)。|
        |数据库密码|填入该数据库账号的密码。 **说明：** 源库信息填写完毕后，您可以单击**数据库密码**后的**测试连接**来验证填入的源库信息是否正确。源库信息填写正确则提示**测试通过**；如果提示**测试失败**，单击**测试失败**后的**诊断**，根据提示调整填写的源库信息。 |
        |连接方式|根据需求选择**非加密连接**或**SSL安全连接**。如果设置为**SSL安全连接**，您需要在配置迁移任务之前开启RDS实例的SSL加密功能，详情请参见[设置SSL加密](https://help.aliyun.com/document_detail/96120.html)。|

6.  配置完成后，单击页面右下角的**授权白名单并进入下一步**。

    此步骤会将DTS服务器的IP地址自动添加到RDS MySQL的白名单中，用于保障DTS服务器能够正常连接目标实例。

7.  选择迁移类型和迁移对象。

    ![选择迁移类型和对象](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/9197549951/p113245.png)

    |配置|说明|
    |:-|:-|
    |迁移类型|    -   如果只需要进行全量迁移，同时选中**结构迁移**和**全量数据迁移**。
    -   如果需要进行不停机迁移，同时选中**结构迁移**、**全量数据迁移**和**增量数据迁移**。本案例同时选中这三种迁移类型。 |
    |迁移对象|在迁移对象框中单击待迁移的对象，然后单击![向右小箭头](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/8502659951/p40698.png)图标将其移动至已选择对象框。 **说明：**

    -   迁移对象选择的粒度为库、表、列。若选择的迁移对象为表或列，其他对象（如视图、触发器、存储过程）不会被迁移至目标库。
    -   默认情况下，迁移对象在目标库中的名称与源库保持一致。如果您需要改变迁移对象在目标库中的名称，需要使用对象名映射功能，详情请参见[库表列映射](/cn.zh-CN/数据迁移/迁移任务管理/库表列映射.md)。
    -   如果使用了对象名映射功能，可能会导致依赖这个对象的其他对象迁移失败。 |

8.  单击页面右下角的**预检查并启动**。

    **说明：**

    -   在迁移任务正式启动之前，会先进行预检查。只有通过预检查，DTS才能迁移数据。
    -   如果预检查失败，单击具体检查项后的![提示](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/8502659951/p47468.png)图标，查看失败详情。根据提示修复后，重新进行预检查。
9.  预检查通过后，单击**下一步**。

10. 在弹出的购买配置确认对话框，选择**链路规格**并选中**数据传输（按量付费）服务条款**。

11. 单击**购买并启动**，迁移任务正式开始。

    -   结构迁移+全量数据迁移

        请勿手动结束迁移任务，否则可能会导致数据不完整。您只需等待迁移任务完成即可，迁移任务会自动结束。

    -   结构迁移+全量数据迁移+增量数据迁移

        迁移任务不会自动结束，您需要手动结束迁移任务。

        **说明：** 请选择合适的时间手动结束迁移任务，例如业务低峰期或准备将业务切换至目标集群时。

        1.  观察迁移任务的进度变更为**增量迁移**，并显示为**无延迟**状态时，将源库停写几分钟，此时**增量迁移**的状态可能会显示延迟的时间。
        2.  等待迁移任务的**增量迁移**再次进入**无延迟**状态后，手动结束迁移任务。

            ![结束增量迁移任务](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/6767559951/p47604.png)


