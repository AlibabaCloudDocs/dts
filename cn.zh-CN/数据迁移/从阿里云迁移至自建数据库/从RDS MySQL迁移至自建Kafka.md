# 从RDS MySQL迁移至自建Kafka

Kafka是应用较为广泛的分布式、高吞吐量、高可扩展性消息队列服务，普遍用于日志收集、监控数据聚合、流式数据处理、在线和离线分析等大数据领域，是大数据生态中不可或缺的产品之一。通过数据传输服务DTS（Data Transmission Service），您可以将RDS MySQL迁移至有公网IP的自建Kafka集群，扩展消息处理能力。

-   已完成Kafka集群的搭建，且Kafka的版本为0.10.1.0~1.0.2版本。
-   Kafka集群的服务端口已开放至公网。

由于数据同步功能对自建Kafka的部署位置要求如下：

-   **ECS上的自建数据库**
-   **通过专线/VPN网关/智能接入网关接入的自建数据库**
-   **无公网IP:Port的数据库（通过数据库网关DG接入）**
-   **通过云企业网CEN接入的自建数据库**

如果Kafka集群的部署位置为本地，且不符合上述场景，您可以将自建Kafka的服务端口开放至公网，然后通过本文介绍的方法来实现数据同步需求。

## 注意事项

-   DTS在执行全量数据迁移时将占用源库和目标库一定的读写资源，可能会导致数据库的负载上升，在数据库性能较差、规格较低或业务量较大的情况下（例如源库有大量慢SQL、存在无主键表或目标库存在死锁等），可能会加重数据库压力，甚至导致数据库服务不可用。因此您需要在执行数据迁移前评估源库和目标库的性能，同时建议您在业务低峰期执行数据迁移（例如源库和目标库的CPU负载在30%以下）。
-   如果源数据库没有主键或唯一约束，且所有字段没有唯一性，可能会导致目标数据库中出现重复数据。
-   迁移对象仅支持数据表。

## 消息格式

迁移到Kafka集群中的数据以avro格式存储，您需要根据avro schema定义进行数据解析，schema定义详情请参见[DTS avro schema定义](https://github.com/LioRoger/subscribe_example/tree/master/avro)。

## 费用说明

|迁移类型|链路配置费用|公网流量费用|
|----|------|------|
|结构迁移和全量数据迁移|不收费。|通过公网将数据迁移出阿里云时将收费，详情请参见[产品定价](/cn.zh-CN/产品定价/产品定价.md)。|
|增量数据迁移|收费，详情请参见[产品定价](/cn.zh-CN/产品定价/产品定价.md)。|

## 操作步骤

1.  登录[数据传输控制台](https://dts.console.aliyun.com/)。

2.  在左侧导航栏，单击**数据迁移**。

3.  在迁移任务列表页面顶部，选择迁移的目标集群所属地域。

    ![选择地域](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/2767559951/p50439.png)

4.  单击页面右上角的**创建迁移任务**。

5.  配置迁移任务的源库及目标库信息。

    ![配置源库和目标库信息](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/3997549951/p146904.png)

    |类别|配置|说明|
    |:-|:-|:-|
    |无|任务名称|DTS会自动生成一个任务名称，建议配置具有业务意义的名称（无唯一性要求），便于后续识别。|
    |源库信息|实例类型|选择**RDS**。|
    |实例地区|选择源RDS实例所属的地域。|
    |实例ID|选择源RDS实例ID。|
    |数据库账号|填入源RDS实例的数据库账号，需具备REPLICATION CLIENT、REPLICATION SLAVE、SHOW VIEW和所有迁移对象的SELECT权限。|
    |数据库密码|填入该数据库账号的密码。|
    |连接方式|根据需求选择**非加密连接**或**SSL安全连接**。如果设置为**SSL安全连接**，您需要提前开启RDS实例的SSL加密功能，详情请参见[设置SSL加密](~~96120~~)。|
    |目标库信息|实例类型|选择**有公网IP的自建数据库**。|
    |实例地区|无需设置。|
    |数据库类型|选择**Kafka**。|
    |主机名或IP地址|填入自建Kafka集群的访问地址，本案例中填入公网地址。|
    |端口|填入Kafka集群提供服务的端口，默认为9092。|
    |数据库账号|填入Kafka集群的用户名，如Kafka集群未开启验证可不填写。|
    |数据库密码|填入Kafka集群用户名的密码，如Kafka集群未开启验证可不填写。|
    |Topic|单击右侧的**获取Topic列表**，然后在下拉框中选择目标Topic。|
    |Kafka版本|选择目标Kafka集群的版本。|
    |连接方式|根据业务及安全需求，选择**非加密连接**或**SCRAM-SHA-256**。|

6.  配置完成后，单击页面右下角的**授权白名单并进入下一步**。

    **说明：** 此步骤会将DTS服务器的IP地址自动添加到源库RDS MySQL的白名单中，用于保障DTS服务器能够正常连接源实例。

7.  配置迁移类型、策略和对象信息。

    ![配置迁移策略和迁移对象](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/3997549951/p146905.png)

    |配置|说明|
    |:-|:-|
    |迁移类型|同时选中**结构迁移**、**全量数据迁移**和**增量数据迁移**。**说明：** 如果未选中**增量数据迁移**，为保障数据一致性，全量数据迁移期间请勿在源库中写入新的数据。 |
    |迁移到Kafka Partition策略|根据业务需求选择迁移的策略，详细介绍请参见[Kafka Partition同步策略说明](/cn.zh-CN/数据同步/同步作业管理/Kafka Partition同步策略说明.md)。|
    |迁移对象|在迁移对象框中单击待迁移的表，然后单击![向右小箭头](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/8502659951/p40698.png)图标将其移动至已选择对象框。**说明：** DTS会自动将表名映射为[步骤5](#step_jq4_gzu_ygs)选择的Topic名称。如需更换迁移的目标Topic，请参见[库表列映射](/cn.zh-CN/数据迁移/迁移任务管理/库表列映射.md)。 |

8.  单击页面右下角的**预检查并启动**。

    **说明：**

    -   在迁移任务正式启动之前，会先进行预检查。只有通过预检查，DTS才能迁移数据。
    -   如果预检查失败，单击具体检查项后的![提示](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/8502659951/p47468.png)图标，查看失败详情。根据提示修复后，重新进行预检查。
9.  预检查通过后，单击**下一步**。

10. 在弹出的购买配置确认对话框，选择**链路规格**并选中**数据传输（按量付费）服务条款**。

11. 单击**购买并启动**，迁移任务正式开始。

    -   结构迁移+全量数据迁移

        请勿手动结束迁移任务，否则可能会导致数据不完整。您只需等待迁移任务完成即可，迁移任务会自动结束。

    -   结构迁移+全量数据迁移+增量数据迁移

        迁移任务不会自动结束，您需要手动结束迁移任务。

        **说明：** 请选择合适的时间手动结束迁移任务，例如业务低峰期或准备将业务切换至目标集群时。

        1.  观察迁移任务的进度变更为**增量迁移**，并显示为**无延迟**状态时，将源库停写几分钟，此时**增量迁移**的状态可能会显示延迟的时间。
        2.  等待迁移任务的**增量迁移**再次进入**无延迟**状态后，手动结束迁移任务。

            ![结束增量迁移任务](https://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/6767559951/p47604.png)


